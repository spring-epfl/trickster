#!/usr/bin/env python3

import sys
sys.path.append('..')

# Ignore warnings.
import warnings
warnings.filterwarnings('ignore')

# Handle library imports.
import pickle
import logging
import numpy as np
import pandas as pd
from os import listdir
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegressionCV
from scipy.sparse import csr_matrix, save_npz, load_npz, issparse
from tqdm import tqdm, trange

from trickster.search import a_star_search, ida_star_search
from trickster.adversarial_helper import *
from trickster.expansion import *

from defaultcontext import with_default_context
from profiled import Profiler, profiled

###########################################
###########################################
###########################################

# Handle global variables.
COUNTER_LIM = 50000
DEBUG_FREQ = 500

logger = None
SEED = 2018
np.random.seed(seed=SEED)

###########################################
###########################################
###########################################

class LogisticRegressionScikitSaliencyOracle:
    def __init__(self, model):
        self.model = model

    def eval(self, _):
        return self.model.coef_[0]

class DistortionBoundReachedError(Exception):
    pass

class ExampleDoesNotExistError(Exception):
    pass

# Functions that performs JSMA search.
@profiled
def find_adversarial_jsma(x, clf, oracle, transformable_feature_idxs, 
    target_confidence=0.5, k=20, return_path=False):
    '''
    Perform adversarial example search using Grosse et al. algorithm based on JSMA.
    '''
    if clf.predict_proba([x])[0, 1] <= target_confidence:
        raise Exception('Initial example is already classified as bening.')
    if return_path:
        path = [x]

    x_star = np.array(x, dtype='float')
    distortions = 0

    while clf.predict_proba([x_star])[0, 1] > target_confidence and distortions < k:
        derivative = oracle.eval(x_star)
        idxs = np.argsort(derivative)

        for i, idx in enumerate(idxs):
            # Check if changing the feature is permitted.
            if x_star[idx] == 0 and idx in transformable_feature_idxs:
                x_star[idx] = 1
                if return_path:
                    path.append(np.array(x_star))
                break
            if i == len(idxs) - 1:
                e = 'Adversarial example is impossible to create. Tried {} distortions.'.format(distortions)
                raise ExampleDoesNotExistError(e)

        distortions += 1

    if distortions == k:
        e = 'Distortion bound {} reached.'.format(k)
        raise DistortionBoundReachedError(e)

    if return_path:
        return x_star, distortions, path
    else:
        return x_star, distortions

###########################################
###########################################
###########################################

# Define experiment helper functions.
def load_transform_data_fn(data_file, **kwargs):
    '''
    Load and preprocess data, returning the examples and labels as numpy.
    '''
    # Try loading saved preprocessed data and classifier.
    with open(data_file, 'rb') as f:
        obj = pickle.load(f)
        X, y = obj['X'], obj['y']

    return X, y, None

def clf_fit_fn(X_train, y_train, data_file, **kwargs):
    # Try loading saved preprocessed data and classifier.
    with open(data_file, 'rb') as f:
        obj = pickle.load(f)
        clf = obj['clf']
    return clf

def get_expansions_fn(_, data_file, feat_count, feature_selection_seed, **kwargs):
    '''
    Define expansions to perform on features and obtain feature indexes.
    '''
    with open(data_file, 'rb') as f:
        obj = pickle.load(f)
        label_encoder = obj['label_encoder']

    features = np.array([c.split('::')[0] for c in label_encoder.classes_])

    # Find indexes of required features in the original feature space.
    idxs_provider = find_substring_occurences(features, 'provider')
    idxs_permission = find_substring_occurences(features, 'permission')
    idxs_activity = find_substring_occurences(features, 'activity')
    idxs_service_receiver = find_substring_occurences(features, 'service_receiver')
    idxs_intent = find_substring_occurences(features, 'intent')

    # Concatenate indexes of transformable features.
    transformable_feature_idxs = idxs_provider + idxs_permission + idxs_activity
    transformable_feature_idxs += idxs_service_receiver + idxs_intent

    # Choose randomly features to perturb.
    np.random.seed(feature_selection_seed)
    transformable_feature_idxs = np.random.choice(transformable_feature_idxs, size=feat_count, replace=False)
    transformable_feature_idxs.sort()

    # Find indexes of required features in the reduced feature space.
    reduced_features = features[transformable_feature_idxs]
    reduced_transformable_feature_idxs = find_substring_occurences(reduced_features, 'provider')
    reduced_transformable_feature_idxs += find_substring_occurences(reduced_features, 'permission')
    reduced_transformable_feature_idxs += find_substring_occurences(reduced_features, 'activity')
    reduced_transformable_feature_idxs += find_substring_occurences(reduced_features, 'service_receiver')
    reduced_transformable_feature_idxs += find_substring_occurences(reduced_features, 'intent')

    # Set required expansions for features.
    expansions = [
        (reduced_transformable_feature_idxs, expand_collection_set)
    ]

    return expansions, transformable_feature_idxs

def benchmark_search_fn(X, idxs, clf, target_confidence,
    transformable_feature_idxs, p_norm, logger_name, **kwargs):
    '''Perform JSMA adversarial example search to benchmark against A* search.'''
    logger = logging.getLogger(logger_name)

    # Dataframe for storing the results.
    results = pd.DataFrame(
        columns=['index', 'found', 'x', 'init_confidence', 'x_adv',
                 'adv_confidence', 'real_cost', 'distortions',
                 'optimal_path', 'difference', 'runtime']
    )

    # Oracle and distortion bound required by the JSMA algorithm.
    k, oracle = 20, LogisticRegressionScikitSaliencyOracle(clf)

    # Find adversarial examples using JSMA and record their costs.
    for i, idx in enumerate(tqdm(idxs, ascii=True)):

        logger.debug('[JSMA] Searching for adversarial example {}/{} using initial observation at index: {}.'
            .format(i, len(idxs), idx))

        if issparse(X):
            x = X[idx].toarray()[0]
        else:
            x = X[idx]

        # Instantiate a profiler to analyse runtime.
        per_example_profiler = Profiler()

        x_adv, adv_found = None, None
        adv_confidence, difference = None, None
        real_cost, distortions = None, None
        runtime, optimal_path = None, None

        with per_example_profiler.as_default():
            try:
                x_adv, distortions, optimal_path = find_adversarial_jsma(
                    x=x,
                    clf=clf,
                    oracle=oracle,
                    transformable_feature_idxs=transformable_feature_idxs,
                    target_confidence=target_confidence,
                    k=k,
                    return_path=True
                )
                adv_found = False if x_adv is None else True

            except (DistortionBoundReachedError, ExampleDoesNotExistError) as e:
                logger.debug('[JSMA] WARN! For observation at index {}: {}'.format(idx, e))

        # Record some basic statistics.
        init_confidence = clf.predict_proba([x])[0, 1]
        runtime_stats = per_example_profiler.compute_stats()
        if 'find_adversarial' in runtime_stats:
            runtime = runtime_stats['find_adversarial']['tot']

        if x_adv is not None:
            logger.debug('[JSMA] Adversarial example found {}/{} found using initial observation at index: {}!'
                .format(i, len(idxs), idx))
            # Compute further statistics.
            adv_confidence = clf.predict_proba([x_adv])[0, 1]
            real_cost = np.linalg.norm(x - x_adv, ord=p_norm)
            difference, = np.where(x != x_adv)

        results.loc[i] = [
            idx, adv_found, x, init_confidence,
            x_adv, adv_confidence, real_cost, distortions,
            optimal_path, difference, runtime
        ]

    return results

###########################################
###########################################
###########################################

# Main function.
if __name__ == "__main__":
    # Setup a custom logger.
    log_file = '../logging/malware_output.log'
    logger = setup_custom_logger(log_file)

    # Define debug parameters (set to None to disable).
    counter_lim = 1000000
    debug_freq = 10000

    # Define experiment parameters.
    data_file = '../scripts/tmp/preprocessed.pickle'
    target_confidence=0.5
    confidence_margin=0.35

    p_norm, q_norm = 1, np.inf
    feature_selection_iterations = 25
    feat_counts = np.arange(200, 49, -50)

    # Perform the experiments.
    logger.info('Starting experiments for the DREBIN malware dataset.')

    for feat_count in feat_counts:

        for i in range(feature_selection_iterations):

            output_file = 'results/malware_{}_{}.pickle'.format(feat_count, i)
            logger.info('Experiment iteration {}/{} using {} features.'
                .format(i, feature_selection_iterations, feat_count))

            result = experiment_wrapper(
                load_transform_data_fn=load_transform_data_fn,
                data_file=data_file,
                feat_count=feat_count,
                feature_selection_seed=SEED+i,
                p_norm=p_norm,
                q_norm=q_norm,
                clf_fit_fn=clf_fit_fn,
                get_expansions_fn=get_expansions_fn,
                expand_quantized_fn=expand_quantized,
                target_confidence=target_confidence,
                confidence_margin=confidence_margin,
                benchmark_search_fn=benchmark_search_fn,
                zero_to_one=False,
                random_state=SEED,
                counter_lim=counter_lim,
                debug_freq=debug_freq,
                logger=logger
            )

            result['feature_count'] = feat_count
            result['feature_selection_iteration'] = i
            result['p_norm'] = p_norm
            result['q_norm'] = q_norm

            assert len(result['search_results']) == len(result['benchmark_results'])

            # Compare our approach with JSMA approach.
            N = len(result['search_results'])

            for j in range(N):
                astr_series = result['search_results'].loc[j]
                jsma_series = result['benchmark_results'].loc[j]

                assert astr_series['index'] == jsma_series['index']
                idx = astr_series['index']

                if astr_series['real_cost'] != jsma_series['real_cost']:
                    logger.info('Real cost differs for A* and JSMA for example at index: {}!'.format(idx))
                if astr_series['path_cost'] != jsma_series['distortions']:
                    logger.info('Path cost differs for A* and JSMA for example at index: {}!'.format(idx))

            # Output results.
            logger.debug('Saving results to {}.'.format(output_file))
            with open(output_file, 'wb') as f:
                pickle.dump(result, f)

    import pdb; pdb.set_trace()
