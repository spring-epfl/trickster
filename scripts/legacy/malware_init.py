#!/usr/bin/env python3

import sys
sys.path.append('..')

# Ignore warnings.
import warnings
warnings.filterwarnings('ignore')

# Handle library imports.
import pickle
import logging
import numpy as np
import pandas as pd
from os import listdir
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegressionCV
from scipy.sparse import csr_matrix, save_npz, load_npz
from tqdm import tqdm, trange

from trickster.search import a_star_search, ida_star_search

from defaultcontext import with_default_context
from profiled import Profiler, profiled

###########################################
###########################################
###########################################

# Handle global variables.

COUNTER_LIM = 50000
DEBUG_FREQ = 100

MANIFEST_FEATURES = [    # corresponds to...
    'provider',          # "Hardware Components"
    'permission',        # "Permissions"
    'activity',          # "Components" (185,729 / 218,951)
    'service_receiver',  # "Components" (33,222  / 218,951)
    'intent'             # "Intents"
]                        # ... in the Grosse et al. paper

MANIFEST_SET = set()

logger = None

SEED = 2018

np.random.seed(seed=SEED)

###########################################
###########################################
###########################################

# Define useful helper functions.

def setup_custom_logger():
    # Set up a logger object to print info to stdout and debug to file.
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    formatter = logging.Formatter(fmt='[%(asctime)s - %(levelname)-4s] %(message)s',
                                  datefmt='%Y-%m-%d %H:%M:%S')

    handler = logging.FileHandler('output.log', mode='w')
    handler.setLevel(logging.DEBUG)
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    handler = logging.StreamHandler(stream=sys.stdout)
    handler.setLevel(logging.INFO)
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    return logger

def load_data(data_folder, hashes_csv, subset=None):
    # Record hashes corresponding to malware applications.
    df = pd.read_csv(hashes_csv)
    malware_hashes = set(df['sha256'])

    # Load the data and record the feature set.
    data, labels, features = [], [], set()
    if subset is None:
        file_paths = listdir(data_folder)
    else:
        file_paths = listdir(data_folder)[:subset]

    for file_path in file_paths:
        with open(data_folder + file_path) as f:
            lines = [x.strip() for x in f]
            if lines == '':
                continue
            data.append(lines)
            features |= set(lines)
            label = 1 if file_path in malware_hashes else 0
            labels.append(label)

    return data, labels, features

def fit_transform(data, features):
    # Fit a label encoder and transform the input data.
    label_encoder = LabelEncoder()
    label_encoder.fit(list(features))
    encoded = [label_encoder.transform(x) for x in data]
    return encoded, label_encoder

def process_data(encoded, labels, features):
    # Create a sparse binary matrix from encoded data.
    indptr = np.cumsum([0] + [len(x) for x in encoded])
    indices = np.concatenate(encoded)
    ones = np.ones(indices.size)

    N, K = len(data), len(features)
    X = csr_matrix((ones, indices, indptr), shape=(N, K))
    y = np.array(labels)
    return X, y

def fit_validate(X_train, y_train):
    # Fit logistic regression by performing a Grid Search with Cross Validation.
    Cs = np.arange(0.5, 1.5, 0.025)
    class_weight = 'balanced' # balanced or None
    scoring = 'accuracy' # accuracy or roc_auc

    clf = LogisticRegressionCV(
        Cs=Cs,
        cv=5,
        n_jobs=-1,
        penalty='l2',
        scoring=scoring,
        class_weight=class_weight,
        random_state=SEED
    )

    clf.fit(X_train, y_train)
    return clf

def set_manifest_set(label_encoder):
    global MANIFEST_SET

    for i, c in enumerate(label_encoder.classes_):
        feature_class = c.split('::')[0]
        if feature_class in MANIFEST_FEATURES:
            MANIFEST_SET.add(i)

###########################################
###########################################
###########################################

# Define useful helper classes.

class LogisticRegressionScikitSaliencyOracle:

    def __init__(self, model):
        self.model = model

    def eval(self, _):
        return self.model.coef_[0]

@with_default_context(use_empty_init=True)
class Counter:
    def __init__(self):
        self.cnt = 0

    def increment(self):
        self.cnt += 1

    def count(self):
        return self.cnt

class Node:

    def __init__(self, x):
        self.root = x

    def expand(self, manifest_set):
        """Generate all children of the current node."""
        # Increment the counter of expanded nodes.
        counter = Counter.get_default()
        counter.increment()

        children = []

        for feat_idx in manifest_set:

            # Skip if the feature is already set.
            if self.root[feat_idx] == 1:
                continue

            child = np.array(self.root)
            child[feat_idx] = 1
            children.append(child)

        return children

    def __repr__(self):
        return 'Node({})'.format(self.root)

###########################################
###########################################
###########################################

# Provide implemention of Algorithm 1 from Grosse et al. paper.

@profiled
def find_adversarial_grosse(x, clf, oracle, manifest_set, target_confidence=0.5, k=20, return_path=False):
    if clf.predict_proba([x])[0, 1] <= target_confidence:
        raise Exception('Initial example is already classified as bening.')

    if return_path:
        path = [x]

    x_star = np.array(x, dtype='intc')
    distortions = 0

    while clf.predict_proba([x_star])[0, 1] > target_confidence and distortions < k:
        derivative = oracle.eval(x_star)
        idxs = np.argsort(derivative)

        for i, idx in enumerate(idxs):

            # Check if changing the feature is permitted.
            if x_star[idx] == 0 and idx in manifest_set:
                x_star[idx] = 1
                if return_path:
                    path.append(np.array(x_star))
                break

            if i == len(idxs) - 1:
                e = 'Adversarial example is impossible to create. Tried {} distortions.'.format(distortions)
                raise Exception(e)

        distortions += 1

    if distortions == k:
        e = 'Distortion bound {} reached.'.format(k)
        raise Exception(e)

    if return_path:
        return x_star, distortions, path
    else:
        return x_star, distortions


# Provide implemention of our algorithm using heuristic and A* search.

@profiled
def find_adversarial(x, clf, search_fn, manifest_set, epsilon, p_norm=1, q_norm=np.inf,
                     target_confidence=0.5, return_path=False, **kwargs):
    """Transform an example until it is classified with target confidence."""

    def expand_fn(x, manifest_set, p_norm=1, **kwargs):
        """Wrap the example in `Node`, expand the node, and compute the costs.

        Returns a list of tuples (child, cost)
        """
        counter = Counter.get_default()
        count = counter.count()

        # Stop searching if counter limit is exceeded.
        if count > COUNTER_LIM:
            raise Exception('Counter limit reached.')

        # Debug.
        if count % DEBUG_FREQ == 0:
            logger.debug('>> (expand_fn) Node counter is: {}.'.format(count))

        node = Node(x, **kwargs)
        children = node.expand(manifest_set)

        costs = [np.linalg.norm(x - c, ord=p_norm) for c in children]
        zipped = list(zip(children, costs))

        return zipped

    def goal_fn(x, clf, target_confidence=0.5):
        """Tell whether the example has reached the goal."""
        # Debug.
        counter = Counter.get_default()
        count = counter.count()
        if count % DEBUG_FREQ == 0:
            logger.debug('>> (goal_fn) Node counter is: {}.'.format(count))

        is_goal = clf.predict_proba([x])[0, 1] <= target_confidence

        return is_goal

    def heuristic_fn(x, clf, manifest_set, epsilon, q_norm=np.inf):
        """Distance to the decision boundary of a logistic regression classifier.

        By default the distance is w.r.t. L1 norm. This means that the denominator
        has to be in terms of the Holder dual norm (`q_norm`), so L-inf. I know,
        this interface is horrible.

        NOTE: The value has to be zero if the example is already on the target side
        of the boundary.
        """
        # Debug.
        counter = Counter.get_default()
        count = counter.count()
        if count % DEBUG_FREQ == 0:
            logger.debug('>> (heuristic_fn start) Node counter is: {}.'.format(count))

        score = clf.decision_function([x])[0]
        if score <= 0:
            return 0.0
        h = np.abs(score) / np.linalg.norm(clf.coef_[0, list(manifest_set)], ord=q_norm)

        return h * epsilon

    def hash_fn(x):
        """Hash function for examples."""
        # Debug.
        counter = Counter.get_default()
        count = counter.count()
        if count % DEBUG_FREQ == 0:
            logger.debug('>> (hash_fn start) Node counter is: {}.'.format(count))

        hashed = hash(x.tostring())

        return hashed


    if clf.predict_proba([x])[0, 1] <= target_confidence:
        raise Exception('Initial example is already classified as bening.')

    return search_fn(
        start_node=x,
        expand_fn=lambda x: expand_fn(x, manifest_set, p_norm=p_norm, **kwargs),
        goal_fn=lambda x: goal_fn(x, clf, target_confidence),
        heuristic_fn=lambda x: heuristic_fn(x, clf, manifest_set, epsilon, q_norm=q_norm),
        hash_fn=hash_fn,
        return_path=return_path
    )

###########################################
###########################################
###########################################

# Write code to run experiments

def jsma_wrapper(X, neg_indices, clf, oracle, manifest_subset, target_confidence, k=20, debug=''):
    jsma_results = {}

    # Find adversarial examples using JSMA and record their costs.
    for idx in tqdm(neg_indices, ascii=True):

        logger.debug('>> {} Locating adversarial example for sample at index: {}...'
                    .format(debug, idx))

        x = X[idx].toarray()[0]

        # Instantiate a profiler to analyse runtime.
        per_example_profiler = Profiler()

        with per_example_profiler.as_default():
            try:
                x_adv_jsma, cost_jsma = find_adversarial_grosse(
                    x,
                    clf,
                    oracle,
                    manifest_subset,
                    target_confidence = target_confidence,
                    k=k
                )

                runtime_jsma = per_example_profiler.compute_stats()['find_adversarial_grosse']['tot']
                jsma_results[idx] = (x_adv_jsma, cost_jsma, runtime_jsma)

            except Exception as e:
                logger.debug('>> {} WARN! JSMA failed for sample at index {} with the following message:\n{}'
                            .format(debug, idx, e))
                continue

    return jsma_results

def find_adv_examples(X, clf, target_confidence, confidence_margin,
                          feat_count, epsilon, p_norm=1, q_norm=np.inf):
    # Define the file location to store results for given epsilon and feature count.
    file_path = 'results/malware_{}_{}.pickle'.format(epsilon, feat_count)

    # List for storing the results.
    results = []

    # Indices of examples classified in the (target_confidence, target_confidence+0.1) range.
    neg_indices, = np.where(
            (clf.predict_proba(X)[:, 1] > target_confidence) &
            (clf.predict_proba(X)[:, 1] <= target_confidence + confidence_margin)
    )

    # Specify how many different subsets of features to choose.
    sampling_count = 25

    for i in range(sampling_count):

        batch_msg = '(Batch: {}; Feats: {}; Epsilon: {})'.format(i, feat_count, epsilon)
        logger.info('>> {} Using JSMA to find adversarial examples for {} samples.'
                        .format(batch_msg, len(neg_indices)))

        # Choose randomly 'feat_count' features to perturb.
        manifest_subset = np.random.choice((list(MANIFEST_SET)), size=feat_count, replace=False)
        assert set(manifest_subset).issubset(MANIFEST_SET)

        # Oracle required by the JSMA algorithm.
        oracle = LogisticRegressionScikitSaliencyOracle(clf)

        # Start by finding adversarial examples using JSMA and record their costs.
        jsma_results = jsma_wrapper(
            X,
            neg_indices,
            clf,
            oracle,
            manifest_subset,
            target_confidence,
            k=1000,
            debug=batch_msg
        )

        logger.info('>> {} JSMA found adversarial examples for {} samples.'.format(batch_msg, len(jsma_results)))

        # Skip this batch if no results are found by JSMA.
        if not len(jsma_results):
            logger.warning('>> {} WARN! Insufficient adversarial examples returned by JSMA. Skipping...'.format(batch_msg))
            continue

        # Keep only those results that have path_costs > 2.
        jsma_results = {k: v for k, v in jsma_results.items() if v[1] > 2}

        if not len(jsma_results):
            logger.warning('>> {} WARN! JSMA did not find adversarial examples with required path cost. Skipping...'.format(batch_msg))
            continue

        # Now only look at the malware samples with lowest path cost according to JSMA.
        jsma_results_sorted = sorted(jsma_results.items(), key=lambda d: d[1][1])[:10]

        logger.info('>> {} Using IDA* search with heuristic to find adversarial examples for {} samples.'
                        .format(batch_msg, len(jsma_results_sorted)))

        for idx, (x_adv_jsma, cost_jsma, runtime_jsma) in tqdm(jsma_results_sorted, ascii=True):

            x = X[idx].toarray()[0]

            # Instantiate a counter for expanded nodes, and a profiler.
            expanded_counter = Counter()
            per_example_profiler = Profiler()

            logger.debug('>> {} Locating adversarial example for sample at index: {}...'
                        .format(batch_msg, idx))

            with expanded_counter.as_default(), per_example_profiler.as_default():
                try:
                    x_adv, cost = find_adversarial(
                        x,
                        clf,
                        ida_star_search,
                        manifest_subset,
                        epsilon,
                        p_norm=1,
                        q_norm=np.inf,
                        target_confidence=target_confidence
                    )

                except Exception as e:
                    logger.debug('>> {} WARN! IDA* search failed for sample at index {} with the following message:\n{}'
                            .format(batch_msg, idx, e))
                    continue

            nodes_expanded = expanded_counter.count()
            runtime = per_example_profiler.compute_stats()['find_adversarial']['tot']
            print('RUNTIME (normal CLF) IS {}'.format(runtime))

            # Construct a new lightweight classifier.
            clf_light = LogisticRegressionCV()
            non_feature_subset = np.setdiff1d(np.arange(X.shape[1]), manifest_subset)
            clf_light.coef_ = clf.coef_[:, manifest_subset]
            clf_light.intercept_ = clf.intercept_ + np.dot(clf.coef_[0, non_feature_subset], x[non_feature_subset])
            import pdb; pdb.set_trace()

            with expanded_counter.as_default(), per_example_profiler.as_default():
                try:
                    x_adv, cost = find_adversarial(
                        x[manifest_subset],
                        clf_light,
                        ida_star_search,
                        manifest_subset,
                        epsilon,
                        p_norm=1,
                        q_norm=np.inf,
                        target_confidence=target_confidence
                    )

                except Exception as e:
                    logger.debug('>> {} WARN! IDA* search failed for sample at index {} with the following message:\n{}'
                            .format(batch_msg, idx, e))
                    continue

            nodes_expanded = expanded_counter.count()
            runtime = per_example_profiler.compute_stats()['find_adversarial']['tot']
            print('RUNTIME (reduced CLF) IS {}'.format(runtime))
            pdb.set_trace()

            confidence_jsma = clf.predict_proba([x_adv_jsma])[0, 1]
            confidence = clf.predict_proba([x_adv])[0, 1]

            result = {
                'index': idx,
                'feat_count': feat_count,
                'manifest_subset': manifest_subset,
                'x_adv_jsma': x_adv_jsma,
                'path_cost_jsma': cost_jsma,
                'confidence_jsma': confidence_jsma,
                'runtime_jsma': runtime_jsma,
                'x_adv': x_adv,
                'path_cost': cost,
                'confidence': confidence,
                'nodes_expanded': nodes_expanded,
                'epsilon': epsilon,
                'runtime': runtime,
                'sampling_count': i
            }

            results.append(result)

            logger.debug(">> {} Saving intermediary results to '{}'.".format(batch_msg, file_path))

            with open(file_path, 'wb') as f:
                pickle.dump(results, f)

            logger.debug(">> {} Intermediary results saved to '{}'.".format(batch_msg, file_path))

    return results

###########################################
###########################################
###########################################

# Main function
if __name__ == "__main__":
    logger = setup_custom_logger()
    file_path = 'tmp/preprocessed.pickle'

    # Try loading saved preprocessed data and classifier.
    try:
        with open(file_path, 'rb') as f:
            logger.info(">> Loading saved preprocessed data...")

            obj = pickle.load(f)
            X, y = obj['X'], obj['y']
            label_encoder = obj['label_encoder']
            clf = obj['clf']

            # Split into training and test sets
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)

    except IOError:
        # Load the data and record the feature set.
        logger.info(">> Loading data from DREBIN dataset...")
        data_folder = '../data/drebin/'
        hashes_csv = '../data/drebin_malware_sha256.csv'
        data, labels, features = load_data(data_folder, hashes_csv, subset=None)

        # Fit a label encoder and transform the input data.
        logger.info(">> Label encoding input data...")
        encoded, label_encoder = fit_transform(data, features)

        # Prepare input data for learning.
        logger.info(">> Preparing data for learning...")
        X, y = process_data(encoded, labels, features)

        # Split into training and test sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)

        # Fit logistic regression by performing a Grid Search with Cross Validation.
        logger.info(">> Fitting logistic regression...")
        clf = fit_validate(X_train, y_train)

        # Save preprocessed data to speed up subsequent experiments.
        obj = {
            'X': X,
            'y': y,
            'label_encoder': label_encoder,
            'clf': clf
        }

        with open(file_path, 'wb') as f:
            pickle.dump(obj, f)

    logger.info(">> Bening samples: {}. Malware samples: {}. Total: {}.".format(y.size - sum(y), sum(y), y.size))

    # Validate the resulting classifier.
    logger.info(">> Resulting training accuracy is: {:.2f}%. Test accuracy is: {:.2f}%."
                .format(clf.score(X_train, y_train)*100, clf.score(X_test, y_test)*100))

    # Set indexes for the features found in the Android manifest.
    set_manifest_set(label_encoder)

    # Number of features to perturb.
    feat_counts = np.arange(10, 21, 1)

    # Epsilons, i.e. coefficients for the A* search heuristic.
    epsilons = [1]

    # Run experiments to compare Grosse et al. with JSMA against our heuristic.
    logger.info("\n>>>> Comparing JSMA against our heuristic...")

    for feat_count in feat_counts:

        for epsilon in epsilons:

            logger.info(">> Running experiments for epsilon: {} and feature count: {}."
                            .format(epsilon, feat_count))

            result = find_adv_examples(
                X,
                clf,
                target_confidence=0.5,
                confidence_margin=0.1,
                feat_count=feat_count,
                epsilon=epsilon,
                p_norm=1,
                q_norm=np.inf
            )
