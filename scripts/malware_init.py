#!/usr/bin/env python3

import sys
sys.path.append('..')

# Ignore warnings.
import warnings
warnings.filterwarnings('ignore')

# Handle library imports.
import pickle
import logging
import numpy as np
import pandas as pd
from os import listdir
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegressionCV
from scipy.sparse import csr_matrix, save_npz, load_npz
from tqdm import tqdm, trange

from trickster.search import a_star_search, ida_star_search

from defaultcontext import with_default_context
from profiled import Profiler, profiled

# Set up a logger object to print info to stdout.
logger = logging.getLogger()
logger.setLevel(logging.INFO)
logger.addHandler(logging.StreamHandler(sys.stdout))

###########################################
###########################################
###########################################

# Handle global variables.

MANIFEST_FEATURES = [    # corresponds to...
    'provider',          # "Hardware Components" 
    'permission',        # "Permissions"
    'activity',          # "Components" (185,729 / 218,951)
    'service_receiver',  # "Components" (33,222  / 218,951)
    'intent'             # "Intents"
]                        # ... in the Grosse et al. paper

MANIFEST_SET = set()

SEED = 2018

np.random.seed(seed=SEED)

###########################################
###########################################
###########################################

# Define useful helper functions.

def load_data(data_folder, hashes_csv, subset=None):
    
    # Record hashes corresponding to malware applications.
    df = pd.read_csv(hashes_csv)
    malware_hashes = set(df['sha256'])
    
    # Load the data and record the feature set.
    data, labels, features = [], [], set()
    if subset is None:
        file_paths = listdir(data_folder)
    else:
        file_paths = listdir(data_folder)[:subset]
        
    for file_path in file_paths:
        with open(data_folder + file_path) as f:
            lines = [x.strip() for x in f]
            if lines == '':
                continue
            data.append(lines)
            features |= set(lines)
            label = 1 if file_path in malware_hashes else 0
            labels.append(label)
            
    return data, labels, features

def fit_transform(data, features):
    
    # Fit a label encoder and transform the input data.
    label_encoder = LabelEncoder()
    label_encoder.fit(list(features))
    encoded = [label_encoder.transform(x) for x in data]
    return encoded, label_encoder

def process_data(encoded, labels, features):
    
    # Create a sparse binary matrix from encoded data.
    indptr = np.cumsum([0] + [len(x) for x in encoded])
    indices = np.concatenate(encoded)
    ones = np.ones(indices.size)

    N, K = len(data), len(features)
    X = csr_matrix((ones, indices, indptr), shape=(N, K))
    y = np.array(labels)   
    return X, y

def fit_validate(X_train, y_train):
    
    # Fit logistic regression by performing a Grid Search with Cross Validation.
    Cs = np.arange(0.5, 1.5, 0.025)
    class_weight = 'balanced' # balanced or None
    scoring = 'accuracy' # accuracy or roc_auc

    clf = LogisticRegressionCV(
        Cs=Cs, 
        cv=5, 
        n_jobs=-1, 
        penalty='l2',
        scoring=scoring,
        class_weight=class_weight,
        random_state=SEED
    )
    
    clf.fit(X_train, y_train)
    return clf

def set_manifest_set(label_encoder):  
    
    global MANIFEST_SET
    
    for i, c in enumerate(label_encoder.classes_):
        feature_class = c.split('::')[0]
        if feature_class in MANIFEST_FEATURES:
            MANIFEST_SET.add(i)

###########################################
###########################################
###########################################

# Define useful helper classes.

class LogisticRegressionScikitSaliencyOracle:
    
    def __init__(self, model):
        self.model = model

    def eval(self, _):
        return self.model.coef_[0]
    
@with_default_context(use_empty_init=True)
class Counter:
    def __init__(self):
        self.cnt = 0
        
    def increment(self):
        self.cnt += 1
        
    def count(self):
        return self.cnt
    
class Node:

    def __init__(self, x):
        self.root = x

    def expand(self, manifest_set):
        """Generate all children of the current node."""
        
        # Increment the counter of expanded nodes.
        counter = Counter.get_default()
        counter.increment()
        if counter.count() % 100 == 0:
            print('>> COUNTER: {}'.format(counter.count()))
        
        children = []
        
        for feat_idx in manifest_set:
            
            # Skip if the feature is already set.
            if self.root[feat_idx] == 1:
                continue
                
            child = np.array(self.root)
            child[feat_idx] = 1
            children.append(child)
            
        return children
    
    def __repr__(self):
        return 'Node({})'.format(self.root)

###########################################
###########################################
###########################################

# Provide implemention of Algorithm 1 from Grosse et al. paper.

@profiled
def find_adversarial_grosse(x, clf, oracle, manifest_set, target_confidence=0.5, k=20, return_path=False):
    
    if clf.predict_proba([x])[0, 1] <= target_confidence:
        raise Exception('Initial example is already classified as bening.')
        
    if return_path:
        path = [x]
        
    x_star = np.array(x, dtype='intc')
    distortions = 0
    
    while clf.predict_proba([x_star])[0, 1] > target_confidence and distortions < k:
        derivative = oracle.eval(x_star)
        idxs = np.argsort(derivative)
        
        for i, idx in enumerate(idxs):
            
            # Check if changing the feature is permitted.
            if x_star[idx] == 0 and idx in manifest_set:
                x_star[idx] = 1
                if return_path:
                    path.append(np.array(x_star))
                break
                
            if i == len(idxs) - 1:
                raise Exception('Adversarial example is impossible to create.')
                
        distortions += 1
        
    if distortions == k:
        raise Exception('Distortion bound reached.')
        
    if return_path:
        return x_star, distortions, path
    else:
        return x_star, distortions
    
    
# Provide implemention of our algorithm using heuristic and A* search.
    
@profiled
def find_adversarial(x, clf, search_fn, manifest_set, epsilon, p_norm=1, q_norm=np.inf,
                     target_confidence=0.5, return_path=False, **kwargs):
    """Transform an example until it is classified with target confidence.""" 
    
    def expand_fn(x, manifest_set, p_norm=1, **kwargs):
        """Wrap the example in `Node`, expand the node, and compute the costs.

        Returns a list of tuples (child, cost)
        """
        
        node = Node(x, **kwargs)
        children = node.expand(manifest_set)
        costs = [np.linalg.norm(x - c, ord=p_norm) for c in children]
        return list(zip(children, costs))

    def goal_fn(x, clf, target_confidence=0.5):
        """Tell whether the example has reached the goal."""
        return clf.predict_proba([x])[0, 1] <= target_confidence

    def heuristic_fn(x, clf, manifest_set, epsilon, q_norm=np.inf):
        """Distance to the decision boundary of a logistic regression classifier.

        By default the distance is w.r.t. L1 norm. This means that the denominator
        has to be in terms of the Holder dual norm (`q_norm`), so L-inf. I know,
        this interface is horrible.

        NOTE: The value has to be zero if the example is already on the target side
        of the boundary.
        """
        score = clf.decision_function([x])[0]
        if score <= 0:
            return 0.0
        h = np.abs(score) / np.linalg.norm(clf.coef_[0, list(manifest_set)], ord=q_norm)    
        return h * epsilon

    def hash_fn(x):
        """Hash function for examples."""
        return hash(x.tostring())

    if clf.predict_proba([x])[0, 1] <= target_confidence:
        raise Exception('Initial example is already classified as bening.')        
    return search_fn(
        start_node=x, 
        expand_fn=lambda x: expand_fn(x, manifest_set, p_norm=p_norm, **kwargs), 
        goal_fn=lambda x: goal_fn(x, clf, target_confidence), 
        heuristic_fn=lambda x: heuristic_fn(x, clf, manifest_set, epsilon, q_norm=q_norm), 
        hash_fn=hash_fn,
        return_path=return_path
    )

###########################################
###########################################
###########################################

# Write code to run experiments

def jsma_wrapper(X, neg_indices, clf, oracle, manifest_subset, target_confidence, k=20):
    
    jsma_results = {}
    
    # Find adversarial examples using JSMA and record their costs.
    for idx in tqdm(neg_indices, ascii=True):
        x = X[idx].toarray()[0] 
        
        # Instantiate a profiler to analyse runtime.
        per_example_profiler = Profiler()

        with per_example_profiler.as_default():
            try:
                x_adv_jsma, cost_jsma = find_adversarial_grosse(
                    x, 
                    clf, 
                    oracle, 
                    manifest_subset, 
                    target_confidence = target_confidence,
                    k=k 
                )
                                
                runtime_jsma = per_example_profiler.compute_stats()['find_adversarial_grosse']['tot']
                jsma_results[idx] = (x_adv_jsma, cost_jsma, runtime_jsma)

            except Exception as e:
                continue
    
    return jsma_results

def find_adv_examples(X, target_confidence, confidence_margin,
                          feat_count, epsilon, p_norm=1, q_norm=np.inf):
    
    # List for storing the results.
    results = []

    # Indices of examples classified in the (target_confidence, target_confidence+0.1) range.
    neg_indices, = np.where(
            (clf.predict_proba(X)[:, 1] > target_confidence) &
            (clf.predict_proba(X)[:, 1] < target_confidence + confidence_margin)
    )
        
    # Specify how many different subsets of features to choose.
    sampling_count = 25
    
    for i in range(sampling_count):
        
        batch_msg = '(Batch: {}; Feats: {}; Epsilon: {})'.format(i, feat_count, epsilon)
        logger.info('>> {} Using JSMA to find adversarial examples for {} samples.'
                        .format(batch_msg, len(neg_indices)))
        
        # Choose randomly 'feat_count' features to perturb.
        manifest_subset = set(np.random.choice((list(MANIFEST_SET)), size=feat_count, replace=False))
        assert manifest_subset.issubset(MANIFEST_SET)

        # Oracle required by the JSMA algorithm.
        oracle = LogisticRegressionScikitSaliencyOracle(clf)

        # Start by finding adversarial examples using JSMA and record their costs.                    
        jsma_results = jsma_wrapper(
            X, 
            neg_indices, 
            clf, 
            oracle, 
            manifest_subset, 
            target_confidence, 
            k=20
        )

        logger.info('>> {} JSMA found adversarial examples for {} samples.'.format(batch_msg, len(jsma_results)))
                    
        # Skip this batch if no results are found by JSMA.
        if not len(jsma_results):
            logger.info('>> {} WARN! Insufficient adversarial examples returned by JSMA. Skipping...'.format(batch_msg))
            continue
            
        # Keep only those results that have path_costs > 2.
        jsma_results = {k: v for k, v in jsma_results.items() if v[1] > 2}
        
        if not len(jsma_results):
            logger.info('>> {} WARN! JSMA did not find adversarial examples with required path cost. Skipping...'.format(batch_msg))
            continue

        # Now only look at the malware samples with lowest path cost according to JSMA.
        jsma_results_sorted = sorted(jsma_results.items(), key=lambda d: d[1][1])[:10]

        logger.info('>> {} Using IDA* search with heuristic to find adversarial examples for 10 samples.'
                        .format(batch_msg, len(jsma_results)))
        
        for idx, (x_adv_jsma, cost_jsma, runtime_jsma) in tqdm(jsma_results_sorted, ascii=True):

            x = X[idx].toarray()[0]

            # Instantiate a counter for expanded nodes, and a profiler.
            expanded_counter = Counter()
            per_example_profiler = Profiler()

            with expanded_counter.as_default(), per_example_profiler.as_default():
                x_adv, cost = find_adversarial(
                    x, 
                    clf, 
                    ida_star_search,
                    manifest_subset, 
                    epsilon,
                    p_norm=1, 
                    q_norm=np.inf,
                    target_confidence=target_confidence
                )

            nodes_expanded = expanded_counter.count()
            runtime = per_example_profiler.compute_stats()['find_adversarial']['tot']

            confidence_jsma = clf.predict_proba([x_adv_jsma])[0, 1]
            confidence = clf.predict_proba([x_adv])[0, 1]

            result = {
                'index': idx, 
                'feat_count': feat_count,
                'manifest_subset': manifest_subset,
                'x_adv_jsma': x_adv_jsma,
                'path_cost_jsma': cost_jsma,
                'confidence_jsma': confidence_jsma,
                'runtime_jsma': runtime_jsma,
                'x_adv': x_adv,
                'path_cost': cost,
                'confidence': confidence,
                'nodes_expanded': nodes_expanded,
                'epsilon': epsilon,
                'runtime': runtime,
                'sampling_count': i
            }
   
            results.append(result)
   
            # Save results.
            file_path = 'results/malware_{}_{}_{}_{}.pickle'.format(epsilon, feat_count, i, idx)
            logger.info(">> Saving intermediary results to '{}'.".format(file_path))

            with open(file_path, 'wb') as f:
                pickle.dump(results, f)
        
    return results

###########################################
###########################################
###########################################

# Main function
if __name__ == "__main__":
        
    file_path = 'tmp/preprocessed.pickle'
    
    # Try loading saved preprocessed data and classifier.
    try:
        with open(file_path, 'rb') as f:
            logger.info(">> Loading saved preprocessed data...")

            obj = pickle.load(f)
            X, y = obj['X'], obj['y']
            label_encoder = obj['label_encoder']
            clf = obj['clf']
            
            # Split into training and test sets
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)
            
    except IOError:
        # Load the data and record the feature set.
        logger.info(">> Loading data from DREBIN dataset...")
        data_folder = '../data/drebin/'
        hashes_csv = '../data/drebin_malware_sha256.csv'
        data, labels, features = load_data(data_folder, hashes_csv, subset=None)

        # Fit a label encoder and transform the input data.
        logger.info(">> Label encoding input data...")
        encoded, label_encoder = fit_transform(data, features)

        # Prepare input data for learning.
        logger.info(">> Preparing data for learning...")
        X, y = process_data(encoded, labels, features)
        
        # Split into training and test sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)
        
        # Fit logistic regression by performing a Grid Search with Cross Validation.
        logger.info(">> Fitting logistic regression...")
        clf = fit_validate(X_train, y_train)   
        
        # Save preprocessed data to speed up subsequent experiments.
        obj = {
            'X': X,
            'y': y,
            'label_encoder': label_encoder,
            'clf': clf
        }
        
        with open(file_path, 'wb') as f:
            pickle.dump(obj, f)
    
    logger.info(">> Bening samples: {}. Malware samples: {}. Total: {}.".format(y.size - sum(y), sum(y), y.size))
    
    # Validate the resulting classifier.
    logger.info(">> Resulting training accuracy is: {:.2f}%. Test accuracy is: {:.2f}%."
                .format(clf.score(X_train, y_train)*100, clf.score(X_test, y_test)*100))
    
    # Set indexes for the features found in the Android manifest.
    set_manifest_set(label_encoder)  
    
    # Number of features to perturb.
    feat_counts = np.arange(30, 71, 10)
    
    # Epsilons, i.e. coefficients for the A* search heuristic.
    epsilons = [1]
    
    # Run experiments to compare Grosse et al. with JSMA against our heuristic.
    logger.info("\n>>>> Comparing JSMA against our heuristic...")  
        
        
    for feat_count in feat_counts:
        
        for epsilon in epsilons:
            
            logger.info(">> Running experiments for epsilon: {} and feature count: {}."
                            .format(epsilon, feat_count))

            result = find_adv_examples(
                X,
                target_confidence=0.5,
                confidence_margin=0.2,
                feat_count=feat_count,
                epsilon=epsilon,
                p_norm=1,
                q_norm=np.inf
            )
          